# -*- coding: utf-8 -*-
"""HANDWRITTEN_DIGIT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CDvLXtClaJWvfgoyX4Z0XgEmO4X0-poz
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist

(X_train, y_train), (X_test, y_test) = mnist.load_data()

X_train = X_train / 255.0
X_test = X_test / 255.0

model = models.Sequential([
    layers.Flatten(input_shape=(28, 28)),
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    X_train, y_train,
    epochs=5,
    validation_split=0.2
)

test_loss, test_acc = model.evaluate(X_test, y_test)
print("Test Accuracy:", test_acc)

import numpy as np

i = 0
plt.imshow(X_test[i], cmap='gray')
plt.title("Actual: " + str(y_test[i]))
plt.show()

pred = model.predict(X_test[i].reshape(1, 28, 28))
print("Predicted:", np.argmax(pred))

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.legend(['Train', 'Validation'])
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.legend(['Train', 'Validation'])
plt.show()